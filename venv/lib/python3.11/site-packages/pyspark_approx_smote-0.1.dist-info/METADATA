Metadata-Version: 2.4
Name: pyspark_approx_smote
Version: 0.1
Summary: Pyspark wrapper of Spark (Scala) Approx SMOTE oversampling algorithm
Home-page: https://github.com/olbapjose/pyspark-approx-smote
Author: Pablo J. Villacorta
Author-email: pjvi@decsai.ugr.es
Keywords: pyspark smote approx-smote
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Build Tools
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3.6
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license-file
Dynamic: summary

# pyspark-approx-smote
Pyspark wrapper of the scala (Spark) version of Approx SMOTE

The original Spark-based version of Approx SMOTE written in Scala can be
found [here](https://github.com/mjuez/approx-smote). The Maven coordinates are `mjuez:approx-smote:jar:1.1.0` 
([available here](https://mvnrepository.com/artifact/mjuez/approx-smote)).


For the wrapper to work, the JAR file must be present in the Spark classpath.

### Installing `pyspark-approx-smote` from this repo:

```shell
git clone https://github.com/olbapjose/pyspark-approx-smote
cd pyspark-approx-smote
pip install -e .
```

### Use example:

```python
from pyspark.ml import Pipeline
from pyspark.ml.feature import VectorAssembler, StringIndexer, SQLTransformer
from pyspark_approx_smote.asmote import ASMOTE

datos = spark.read.option("inferSchema", "true").option("header", "false")\
    .csv("adult.csv")\
    .withColumnRenamed("_c14", "target")\
    .dropna()

num_cols = [c for (c, tipo) in datos.dtypes if tipo != "string"]

string_indexer = StringIndexer(inputCol="target", outputCol="targetIndexed")
vector_assembler = VectorAssembler(inputCols=num_cols, outputCol="features")
sql_transformer = SQLTransformer(statement="SELECT targetIndexed, features FROM __THIS__")

asmote = ASMOTE(
    featuresCol="features",
    labelCol="targetIndexed",
    seed=1234
)

datos.groupBy("target").count().show()
pipeline = Pipeline(stages=[vector_assembler, string_indexer, sql_transformer, asmote])
datos_transformados = pipeline.fit(datos).transform(datos)
datos_transformados.groupBy("targetIndexed").count().show()

```



