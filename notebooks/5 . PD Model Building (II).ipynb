{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4090bcb",
   "metadata": {},
   "source": [
    "This notebook will train a logistic PD model on our Lending Club dataset. \n",
    "We’ll cover:\n",
    "\n",
    "1. Chronological train / OOT split\n",
    "2. Class balancing (SMOTE-style oversampling)\n",
    "3. Feature assembly & standardisation\n",
    "4. Logistic regression\n",
    "5. Evaluation: AUC & KS\n",
    "\n",
    "At each step, there will be explanations of *why* that particular step is important for a robust, production-grade PD model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe24a5",
   "metadata": {},
   "source": [
    "## 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52eaf21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/14 15:32:07 WARN Utils: Your hostname, Chengs-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 10.106.14.41 instead (on interface en0)\n",
      "25/07/14 15:32:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/lunlun/Downloads/Github/Credit-Risk-Modeling-PySpark/venv/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /Users/lunlun/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /Users/lunlun/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-55557f7f-a7a9-4ddd-a317-2f0eb25e30a0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      ":: resolution report :: resolve 95ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-55557f7f-a7a9-4ddd-a317-2f0eb25e30a0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "25/07/14 15:32:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Import function to start Spark\n",
    "from init_spark import start_spark\n",
    "spark = start_spark()\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, count, desc, isnan, isnull, lit, length, trim, lower, upper, to_date, concat_ws,  regexp_extract, sum \n",
    ")\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, IntegerType, DateType, NumericType\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda8db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(spark://10.106.14.41:60816/jars/io.delta_delta-spark_2.13-4.0.0.jar, spark://10.106.14.41:60816/jars/org.antlr_antlr4-runtime-4.13.1.jar, spark://10.106.14.41:60816/jars/io.delta_delta-storage-4.0.0.jar)\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext._jsc.sc().listJars())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f648bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9836fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/14 15:32:10 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>loan_amnt_annual_inc_ratio</th>\n",
       "      <th>tl_op12m_inq6m</th>\n",
       "      <th>dti_inq</th>\n",
       "      <th>dti_bc_util</th>\n",
       "      <th>revol_util_fractional</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>acc_open24m_revol_util</th>\n",
       "      <th>loan_amnt_bc_open_to_buy</th>\n",
       "      <th>dti_verified_multiply</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>default_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13600.0</td>\n",
       "      <td>0.339242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>1506.780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>321.5</td>\n",
       "      <td>2.080774</td>\n",
       "      <td>19.80</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1916.392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>48.3</td>\n",
       "      <td>0.367625</td>\n",
       "      <td>33.68</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11900.0</td>\n",
       "      <td>0.207315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.09</td>\n",
       "      <td>436.860</td>\n",
       "      <td>32.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.105023</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.416649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.95</td>\n",
       "      <td>257.895</td>\n",
       "      <td>49.8</td>\n",
       "      <td>662.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>3.211304</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>0.211396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2600.794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.014625</td>\n",
       "      <td>27.58</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>0.245391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>321.555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>121.8</td>\n",
       "      <td>0.976443</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10900.0</td>\n",
       "      <td>0.266663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1414.266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>255.2</td>\n",
       "      <td>5.537099</td>\n",
       "      <td>21.14</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>24400.0</td>\n",
       "      <td>0.049999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.10</td>\n",
       "      <td>2161.295</td>\n",
       "      <td>73.3</td>\n",
       "      <td>722.0</td>\n",
       "      <td>293.2</td>\n",
       "      <td>0.509061</td>\n",
       "      <td>27.05</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>0.198657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2435.602</td>\n",
       "      <td>82.9</td>\n",
       "      <td>697.0</td>\n",
       "      <td>165.8</td>\n",
       "      <td>11.421971</td>\n",
       "      <td>29.38</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>0.181810</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.86</td>\n",
       "      <td>171.789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.469428</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mo_sin_rcnt_tl  num_tl_op_past_12m  percent_bc_gt_75  total_bc_limit  \\\n",
       "0             2.0                 3.0              50.0         13600.0   \n",
       "1            19.0                 0.0              25.0         38000.0   \n",
       "2             3.0                 2.0              50.0         11900.0   \n",
       "3             4.0                 1.0              50.0          6500.0   \n",
       "4            36.0                 0.0             100.0          9500.0   \n",
       "5             5.0                 1.0              25.0         15900.0   \n",
       "6             8.0                 2.0              50.0         10900.0   \n",
       "7             2.0                 2.0              66.7         24400.0   \n",
       "8            15.0                 0.0              50.0          5700.0   \n",
       "9             5.0                 3.0              25.0         10300.0   \n",
       "\n",
       "   loan_amnt_annual_inc_ratio  tl_op12m_inq6m  dti_inq  dti_bc_util  \\\n",
       "0                    0.339242             3.0    19.80     1506.780   \n",
       "1                    0.105700             0.0     0.00     1916.392   \n",
       "2                    0.207315             2.0     8.09      436.860   \n",
       "3                    0.416649             1.0     4.95      257.895   \n",
       "4                    0.211396             0.0     0.00     2600.794   \n",
       "5                    0.245391             0.0     0.00      321.555   \n",
       "6                    0.266663             0.0     0.00     1414.266   \n",
       "7                    0.049999             4.0    54.10     2161.295   \n",
       "8                    0.198657             0.0     0.00     2435.602   \n",
       "9                    0.181810             6.0    19.86      171.789   \n",
       "\n",
       "   revol_util_fractional  fico_score  acc_open24m_revol_util  \\\n",
       "0                    0.0       677.0                   321.5   \n",
       "1                    0.0       722.0                    48.3   \n",
       "2                   32.0       677.0                   128.0   \n",
       "3                   49.8       662.0                    99.6   \n",
       "4                    0.0       742.0                     0.0   \n",
       "5                    0.0       672.0                   121.8   \n",
       "6                    0.0       662.0                   255.2   \n",
       "7                   73.3       722.0                   293.2   \n",
       "8                   82.9       697.0                   165.8   \n",
       "9                    0.0       702.0                    52.0   \n",
       "\n",
       "   loan_amnt_bc_open_to_buy  dti_verified_multiply     issue_d  default_status  \n",
       "0                  2.080774                  19.80  2016-07-01               0  \n",
       "1                  0.367625                  33.68  2016-07-01               0  \n",
       "2                  3.105023                   0.00  2016-07-01               0  \n",
       "3                  3.211304                   4.95  2016-07-01               0  \n",
       "4                 11.014625                  27.58  2016-07-01               0  \n",
       "5                  0.976443                   0.00  2016-07-01               0  \n",
       "6                  5.537099                  21.14  2016-07-01               0  \n",
       "7                  0.509061                  27.05  2016-07-01               0  \n",
       "8                 11.421971                  29.38  2016-07-01               0  \n",
       "9                  0.469428                   0.00  2016-07-01               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check if Gold Delta is accessible for subsequent model building \n",
    "df = spark.read.format(\"delta\")\\\n",
    "    .load(\"../data/gold/ready_for_pd_modeling\")\n",
    "    \n",
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2573a6",
   "metadata": {},
   "source": [
    "## 1. Chronological Training / Out-of-Time Split \n",
    "Out of Time Split refers to separating datasets into distinct time periods for model training and model testing stage. This is especially important, since it mitigates against data leakage. For example, if our training and testing splits are random, the model may 'peek' into future defaults while being trained, resulting in a model that is only good in training data, and not test data. On the contrary, if we use out-of-time splits, the model is only being trained on 2022 data, while being tested on 2023 data. This ensures that our model is only being trained on past predictions, to make a reasonably accurate forecast of credit risk on future loans. Our model can then steer itself away from being labeled as 'overfitted model', and be a model that truly generalises across data points to capture real patterns of borrowers / loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3f1490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting at ≈ 2018-02-01\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime, col\n",
    "\n",
    "# 1) Convert to numeric timestamp\n",
    "df_ts = df.withColumn(\"issue_ts\", unix_timestamp(col(\"issue_d\")))\n",
    "\n",
    "# 2) Compute the 80th percentile of that timestamp\n",
    "quantiles = df_ts.stat.approxQuantile(\"issue_ts\", [0.8], 0.01)\n",
    "cut_ts = quantiles[0]  # e.g. 1672531200\n",
    "\n",
    "# 3) Convert back to a human date\n",
    "cut_date = (\n",
    "    df_ts\n",
    "    .select(from_unixtime(lit(cut_ts), \"yyyy-MM-dd\").alias(\"cut_date\"))\n",
    "    .first()[\"cut_date\"]\n",
    ")\n",
    "\n",
    "print(f\"Splitting at ≈ {cut_date}\")\n",
    "\n",
    "# 4) Train-test split\n",
    "train_df = df.filter(col(\"issue_d\") < cut_date) # train using 80% of the data before cut-off data at 80% \n",
    "test_df  = df.filter(col(\"issue_d\") >= cut_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e576e066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|default_status|  count|\n",
      "+--------------+-------+\n",
      "|             1| 229904|\n",
      "|             0|1506960|\n",
      "+--------------+-------+\n",
      "\n",
      "+--------------+------+\n",
      "|default_status| count|\n",
      "+--------------+------+\n",
      "|             1|  6114|\n",
      "|             0|440210|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = df.filter(col(\"issue_d\") < cut_date)\n",
    "\n",
    "# Train and Test Datasets should have both default and non-defaulted class\n",
    "train_df.groupBy(\"default_status\").count().show()\n",
    "test_df.groupBy(\"default_status\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76577591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== First / last 5 rows of train_df issue_d ===\n",
      "+----------+\n",
      "|   issue_d|\n",
      "+----------+\n",
      "|2007-06-01|\n",
      "|2007-07-01|\n",
      "|2007-07-01|\n",
      "|2007-07-01|\n",
      "|2007-07-01|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "+----------+\n",
      "|   issue_d|\n",
      "+----------+\n",
      "|2018-01-01|\n",
      "|2018-01-01|\n",
      "|2018-01-01|\n",
      "|2018-01-01|\n",
      "|2018-01-01|\n",
      "+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== First / last 5 rows of train_df issue_d ===\")\n",
    "train_df.select(\"issue_d\").orderBy(col(\"issue_d\").asc()).show(5)\n",
    "train_df.select(\"issue_d\").orderBy(col(\"issue_d\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdca55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== First / last 5 rows of test_df issue_d ===\n",
      "+----------+\n",
      "|   issue_d|\n",
      "+----------+\n",
      "|2018-02-01|\n",
      "|2018-02-01|\n",
      "|2018-02-01|\n",
      "|2018-02-01|\n",
      "|2018-02-01|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "+----------+\n",
      "|   issue_d|\n",
      "+----------+\n",
      "|2018-12-01|\n",
      "|2018-12-01|\n",
      "|2018-12-01|\n",
      "|2018-12-01|\n",
      "|2018-12-01|\n",
      "+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== First / last 5 rows of test_df issue_d ===\")\n",
    "test_df.select(\"issue_d\").orderBy(col(\"issue_d\").asc()).show(5)\n",
    "test_df.select(\"issue_d\").orderBy(col(\"issue_d\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4723615",
   "metadata": {},
   "source": [
    "## 2. Feature Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59069e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "# 1. Combine features into 1 single vector column named 'features_raw' \n",
    "numeric_cols = [f.name for f in df.schema.fields if f.name not in ('id', 'issue_d', 'default_status')]\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features_raw\")\n",
    "train_df_assembled = assembler.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b0f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>loan_amnt_annual_inc_ratio</th>\n",
       "      <th>tl_op12m_inq6m</th>\n",
       "      <th>dti_inq</th>\n",
       "      <th>dti_bc_util</th>\n",
       "      <th>revol_util_fractional</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>acc_open24m_revol_util</th>\n",
       "      <th>loan_amnt_bc_open_to_buy</th>\n",
       "      <th>dti_verified_multiply</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>default_status</th>\n",
       "      <th>features_raw</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>16300.0</td>\n",
       "      <td>0.340894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>857.4</td>\n",
       "      <td>51.5</td>\n",
       "      <td>662.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1.380707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.0, 2.0, 37.5, 16300.0, 0.3408935957456479, ...</td>\n",
       "      <td>[-0.23606680234201252, -0.04487527863868763, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>16300.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>223.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>812.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.920471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.0, 2.0, 37.5, 16300.0, 0.024999875000624998...</td>\n",
       "      <td>[-0.23606680234201252, -0.04487527863868763, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>16300.0</td>\n",
       "      <td>0.071621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>862.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>797.0</td>\n",
       "      <td>57.6</td>\n",
       "      <td>0.975700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.0, 2.0, 37.5, 16300.0, 0.07162065377494899,...</td>\n",
       "      <td>[-0.23606680234201252, -0.04487527863868763, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>16300.0</td>\n",
       "      <td>0.166661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1118.4</td>\n",
       "      <td>47.1</td>\n",
       "      <td>702.0</td>\n",
       "      <td>188.4</td>\n",
       "      <td>0.920471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.0, 2.0, 37.5, 16300.0, 0.16666111129629013,...</td>\n",
       "      <td>[-0.23606680234201252, -0.04487527863868763, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>16300.0</td>\n",
       "      <td>0.204163</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.24</td>\n",
       "      <td>1027.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>747.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>2.255155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.0, 2.0, 37.5, 16300.0, 0.20416326394560091,...</td>\n",
       "      <td>[-0.23606680234201252, -0.04487527863868763, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mo_sin_rcnt_tl  num_tl_op_past_12m  percent_bc_gt_75  total_bc_limit  \\\n",
       "0             6.0                 2.0              37.5         16300.0   \n",
       "1             6.0                 2.0              37.5         16300.0   \n",
       "2             6.0                 2.0              37.5         16300.0   \n",
       "3             6.0                 2.0              37.5         16300.0   \n",
       "4             6.0                 2.0              37.5         16300.0   \n",
       "\n",
       "   loan_amnt_annual_inc_ratio  tl_op12m_inq6m  dti_inq  dti_bc_util  \\\n",
       "0                    0.340894             0.0     0.00        857.4   \n",
       "1                    0.025000             0.0     0.00        223.2   \n",
       "2                    0.071621             0.0     0.00        862.2   \n",
       "3                    0.166661             0.0     0.00       1118.4   \n",
       "4                    0.204163             4.0    34.24       1027.2   \n",
       "\n",
       "   revol_util_fractional  fico_score  acc_open24m_revol_util  \\\n",
       "0                   51.5       662.0                   206.0   \n",
       "1                    0.7       812.0                     2.8   \n",
       "2                   14.4       797.0                    57.6   \n",
       "3                   47.1       702.0                   188.4   \n",
       "4                    8.1       747.0                    32.4   \n",
       "\n",
       "   loan_amnt_bc_open_to_buy  dti_verified_multiply     issue_d  \\\n",
       "0                  1.380707                    0.0  2007-06-01   \n",
       "1                  0.920471                    0.0  2007-07-01   \n",
       "2                  0.975700                    0.0  2007-07-01   \n",
       "3                  0.920471                    0.0  2007-07-01   \n",
       "4                  2.255155                    0.0  2007-07-01   \n",
       "\n",
       "   default_status                                       features_raw  \\\n",
       "0               0  [6.0, 2.0, 37.5, 16300.0, 0.3408935957456479, ...   \n",
       "1               0  [6.0, 2.0, 37.5, 16300.0, 0.024999875000624998...   \n",
       "2               0  [6.0, 2.0, 37.5, 16300.0, 0.07162065377494899,...   \n",
       "3               0  [6.0, 2.0, 37.5, 16300.0, 0.16666111129629013,...   \n",
       "4               0  [6.0, 2.0, 37.5, 16300.0, 0.20416326394560091,...   \n",
       "\n",
       "                                            features  \n",
       "0  [-0.23606680234201252, -0.04487527863868763, -...  \n",
       "1  [-0.23606680234201252, -0.04487527863868763, -...  \n",
       "2  [-0.23606680234201252, -0.04487527863868763, -...  \n",
       "3  [-0.23606680234201252, -0.04487527863868763, -...  \n",
       "4  [-0.23606680234201252, -0.04487527863868763, -...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Scale Features (so Logistic Regression won't be affected by scale)\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(train_df_assembled)\n",
    "train_df_scaled = scaler_model.transform(train_df_assembled)\n",
    "train_df_scaled.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c7c91",
   "metadata": {},
   "source": [
    "## 3. Class-Weighting Class Imbalance \n",
    "\n",
    "Credit datasets are inherently imbalanced, i.e default rates often make up ≤ 10% of observations. A normal classifier will often be biased towards the majority of non-default classes. Often, there will be seemingly highly predictive results, such as 99% accuracy. However, it is important to note that Accuracy can be deceptive. For example, since accuracy is defined by correct predictions / all predictions, \n",
    "if only 5% of borrowers default, a classifier which always predicts 'non-default' will be correct 95% of the time. This model is hence unhelpful in identifying defaulters. \n",
    "\n",
    "To deal with class imbalance, we do have a few options, i.e. SMOTE (oversampling) and class-weighting. However, the creation of new feature vectors in SMOTE is computationally expensive and my local machine couldn't handle SMOTE and the loading of the 4 million rows dataset. Though there are big data libraries to conduct SMOTE out there like ASMOTE, such libraries support only Pyspark 3.x.x, which is uncompatible with our `delta-lake`. Class weighting solves this by making the model pay more attention to the rare class (defaults) without generating fake data.\n",
    "\n",
    "Specifically, every training observation is given a weight. These weights will tell the model how important each row is. Ultimately, each default can then contribute as much influence as a non-default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc8183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compute class weights and assign to column\n",
    "count_pos = train_df_scaled.filter(\"default_status == 1\").count()\n",
    "count_neg = train_df_scaled.filter(\"default_status == 0\").count()\n",
    "balancing_ratio = count_neg / count_pos # non-default is > default \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6fe033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[mo_sin_rcnt_tl: double, num_tl_op_past_12m: double, percent_bc_gt_75: double, total_bc_limit: double, loan_amnt_annual_inc_ratio: double, tl_op12m_inq6m: double, dti_inq: double, dti_bc_util: double, revol_util_fractional: double, fico_score: double, acc_open24m_revol_util: double, loan_amnt_bc_open_to_buy: double, dti_verified_multiply: double, issue_d: date, default_status: int, features_raw: vector]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Select vector column, target column, and newly created class_weight \n",
    "train_df_weighted = train_df_scaled.withColumn(\n",
    "    \"class_weight\",\n",
    "    F.when(F.col(\"default_status\") == 1, balancing_ratio).otherwise(1.0)\n",
    ").select(\"features\", \"default_status\", \"class_weight\")\n",
    "train_df_assembled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c48612",
   "metadata": {},
   "source": [
    "## 4. Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960a0ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/14 15:32:19 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Step 5: Train logistic regression with class weights\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"default_status\",\n",
    "    weightCol=\"class_weight\"\n",
    ")\n",
    "model = lr.fit(train_df_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90973b44",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a99b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6324578397126118"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Step 6: Prepare OOT data (assemble + scale using same transformers)\n",
    "oot_df_assembled = assembler.transform(test_df)\n",
    "oot_df_scaled = scaler_model.transform(oot_df_assembled).select(\"features\", \"default_status\")\n",
    "\n",
    "# Step 7: Predict and evaluate on OOT\n",
    "predictions = model.transform(oot_df_scaled)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"default_status\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
