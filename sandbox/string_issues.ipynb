{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ed89801-2964-4e65-8da3-7c3a8e454f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# String Formatting EDA (Lending Club)\n",
    "This notebook aims to use **RapidFuzz** to quickly find out issues in string columns in the Bronze Delta Table Lending Club Dataset. After finding out such issues, string formatting issues will then be resolved via the Medallion Architecture Data Cleaning Pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e7118ce-825d-4647-abad-2ba222f567dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d599252d-b6e3-48d6-b65d-58217986af6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col, trim, lower, count, desc\n",
    "from rapidfuzz import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5f32172-eb35-4034-a9b5-0799b8f16350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88e7c3f7-d263-428d-8dc6-9a95ba3629b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from Bronze Delta Table (Uncleaned & Raw)\n",
    "df = spark.read.format(\"delta\").load(\"bronze_raw_lendingclub_data\")\n",
    "df.printSchema() \n",
    "\n",
    "# Adjust the path to wherever your raw Lending Club Delta table sits\n",
    "# raw_df = spark.read.format(\"delta\").load(\"/mnt/bronze/lending_club\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e0fe83-e896-4712-9a03-04523f57157d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Identify all String Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c303f032-b706-4160-b29f-f1bbc0a040e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_string_cols = [\n",
    "    f.name\n",
    "    for f in df.schema.fields\n",
    "    if isinstance(f.dataType, StringType)\n",
    "]\n",
    "print(\"String columns:\", all_string_cols)\n",
    "\n",
    "\n",
    "print(f\"Number of String Columns: {len(all_string_cols)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "879ce62e-138f-4e4b-8f96-e624ffedcd0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Identify Number of Distinct Values Per String Column\n",
    "The following code prints how many distinct values each string column has, so we can decide which columns we can tackle with fuzzy grouping with Rapid Fuzz (more computationally expensive) and which allows manual cleaning (lower effort and cost). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56f6f2ab-271c-4876-bef8-3768811f10cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col_num, col_name in enumerate(all_string_cols, 1): # starts from col_num = 1 \n",
    "    distinct_count = df.select(col_name).distinct().count() \n",
    "    print(f\"{col_num:02d}. {col_name} -> {distinct_count:6d} distinct values\" ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e480d9e3-8e9b-41bf-9e03-f9406762bc4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Show Top Frequent N Values Per String Column \n",
    "Before doing any fuzzy grouping, we can see the top frequent values per column in strings. An example would be `home_ownership` showing 'rent', 'Rent' and 'RENT '. This will affect subsequent analysis and skew machine learning models. \n",
    "\n",
    "As such, the following approach allows me to check if a column has obvious variants, guiding our decisions on which columns to cluster with RapidFuzz to reduce computational expenses. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eacf298c-8272-41dd-a277-97bda7f6e4d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def show_raw_top_values(df, column, top_n=30):\n",
    "    print(f\"\\nTop {top_n} raw values for column '{column}':\")\n",
    "    (\n",
    "        df\n",
    "        .groupBy(col(column))\n",
    "        .count()\n",
    "        .orderBy(desc(\"count\"))\n",
    "        .limit(top_n)\n",
    "        .show(truncate=False)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74028b1-65cd-442e-863b-1b827e3a7b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. RapidFuzz String Similarity Matching Function\n",
    "Now that we have drilled down to the columns that have inconsistent spelling and formats, we would want to group similar strings together and map similar variants to 1 single string value. \n",
    "\n",
    "RapidFuzz clusters items that exceed the similarity threshold. It is a library that is better than FuzzyWuzzy for string matching, which allows better performance in big data environments. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57f44cb7-9f13-470b-9373-3b78a698dce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_fuzzy_groups(distinct_values, threshold=85):\n",
    "    \"\"\"\n",
    "    Given a Python list of distinct strings from a column, return a dict mapping each string\n",
    "    to a chosen 'canonical' string (first occurence). Two strings with similarity ≥ threshold\n",
    "    collapse into the same 'canonical string'.\n",
    "\n",
    "    Output:\n",
    "    {\n",
    "        \"Rent\": \"Rent\",\n",
    "        \"RENT\": \"Rent\",\n",
    "        \"rent\": \"Rent\",\n",
    "        \"Own\": \"Own\",\n",
    "        \"own\": \"Own\",\n",
    "        \"mortgag\": \"mortgag\",\n",
    "        \"Mortgage\": \"mortgag\"\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    canonical_list = [] # accepted clean values \n",
    "    mapping = {}\n",
    "\n",
    "    for val in distinct_values:\n",
    "        \n",
    "        # Skip whitespaces, empty strings or None \n",
    "        if not val or val.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        match, score, _ = process.extractOne(val, canonical_list, score_cutoff=threshold)\n",
    "\n",
    "        # If high matching / similarity, then add to mapping dict key, e.g. 'ReNt' -> 'rent' \n",
    "        # Else (low similarity), add to canonical_list (fresh new <string>)\n",
    "        if match:\n",
    "            mapping[val] = match\n",
    "        else:\n",
    "            canonical_list.append(val)\n",
    "            mapping[val] = val\n",
    "\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02b501ed-6cde-497b-8ad0-8f361e428354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6.1 RapidFuzz String Matching Test (1 column)\n",
    "\n",
    "The following code demonstrates how fuzzy matching works, for learning purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c0aeaaf-bfc9-4802-a5a6-00b7e0f8f0ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Choose one column you want to test fuzzy grouping on\n",
    "example_column = \"home_ownership\"\n",
    "\n",
    "# Step 1: All Row Objects in this column \n",
    "distinct_vals = df.select(example_column).distinct().collect()\n",
    "\n",
    "# Step 2: Row objects -> Raw Strings (keeping None values as-is) (Fuzzy-matching only accepts strings)\n",
    "distinct_vals = [row[example_column] for row in distinct_vals]\n",
    "\n",
    "# Step 3: Run fuzzy grouping on non-null values only, default_threshold=85% \n",
    "threshold = 85\n",
    "mapping_dict = get_fuzzy_groups([v for v in distinct_vals if v is not None], threshold=threshold)\n",
    "\n",
    "# Step 4: Ensures 'Rent' : ['Rent', 'rEnt', 'RENT'] in fuzzy_groups \n",
    "fuzzy_groups = defaultdict(list) # auto-creates key, if key is not in the dictionary \n",
    "for original_val, canonical_val in mapping_dict.items():\n",
    "    fuzzy_groups[canonical_val].append(original_val)\n",
    "\n",
    "# Output\n",
    "print(f\"\\nFuzzy groups for column: '{example_column}' (threshold = {threshold})\")\n",
    "for canonical, group_members in fuzzy_groups.items():\n",
    "\n",
    "    # If there are many variants of 'Rent'\n",
    "    if len(group_members) > 1:\n",
    "        print(f\"  Canonical: '{canonical}' ← {group_members}\")\n",
    "\n",
    "    # Distinct Value (No variants)\n",
    "    else:\n",
    "        print(f\"  (Solo) '{canonical}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c42d40bd-086d-47e5-bf5a-e73044662e62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6.2 RapidFuzz Fuzzy Grouping (String Columns) \n",
    "In this section, we will **skipping fuzzy grouping** for some columns, due to data mismatch. For example, `loan_term` should be skipped since it has numeric data, but it is referenced to as a string in the Bronze Delta Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31fdd271-7607-44f5-8de7-9d229d25f5de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Skipping selected columns \n",
    "# skip_fuzzy_columns = [\"term\", \"zip_code\", \"int_rate\", \"loan_amnt\"]\n",
    "\n",
    "\n",
    "# # For each column (not skipped), display top 10 values and count of records \n",
    "# for i, col_name in enumerate([c for c in all_string_cols if c not in skip_fuzzy_columns], 1):\n",
    "#     print(f\"\\n{i}. Column: '{col_name}'\")\n",
    "\n",
    "#     # Show top 10 values of each column \n",
    "#     df.groupBy(col_name).count().orderBy(\"count\", ascending=False).show(10, truncate=False)\n",
    "\n",
    "#     # Get distinct values (excluding nulls)\n",
    "#     values = df.select(col_name).distinct().collect()\n",
    "#     values = [row[col_name] for row in values if row[col_name] is not None]\n",
    "\n",
    "#     # Fuzzy match similar values\n",
    "#     groups = get_fuzzy_groups(values, threshold=90)\n",
    "\n",
    "#     # Print fuzzy clusters\n",
    "#     grouped = defaultdict(list)\n",
    "#     for original, canonical in groups.items():\n",
    "#         grouped[canonical].append(original)\n",
    "\n",
    "#     for canon, variants in grouped.items():\n",
    "#         if len(variants) > 1:\n",
    "#             print(f\"  Canonical: '{canon}' ← {variants}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b33ecad-d7f8-457a-8c06-62cfe59cf107",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Export String Mapping Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7bf79a5-70d0-4fef-b104-dc8acbf42b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "string_issues",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
